# ğŸ§  Data Lake Local com Trino, Hive, Delta Lake e Superset

Este projeto Ã© uma demonstraÃ§Ã£o prÃ¡tica de como construir um **Data Lake local** utilizando ferramentas **open source** â€” tudo rodando na sua mÃ¡quina, com Docker.

O objetivo Ã© simular um ambiente real de engenharia de dados, onde vocÃª pode gravar dados em Delta Lake, catalogar com Hive Metastore, consultar com Trino e visualizar no Superset.

---

## ğŸ”§ Stack Utilizada

- [MinIO](https://min.io/) - Armazenamento S3 local
- [Hive Metastore](https://cwiki.apache.org/confluence/display/Hive/Design) - CatÃ¡logo de metadados
- [Trino](https://trino.io/) - Engine de consulta distribuÃ­da
- [Superset](https://superset.apache.org/) - VisualizaÃ§Ã£o e dashboards
- [PostgreSQL](https://www.postgresql.org/) - Metastore do Hive e backend do Superset
- [PySpark + Delta Lake](https://delta.io/) - Escrita de dados em formato Delta
- [Docker Compose](https://docs.docker.com/compose/) - OrquestraÃ§Ã£o dos containers

---

## ğŸ“‚ Estrutura do Projeto

```
â”œâ”€â”€ data
â”‚Â Â  â””â”€â”€ trino
â”‚Â Â      â””â”€â”€ etc
â”œâ”€â”€ poc
â”‚Â Â  â”œâ”€â”€ executar_trino.sh
â”‚Â Â  â”œâ”€â”€ reinciar_docker.sh
â”‚Â Â  â”œâ”€â”€ trino-cli-400-executable.jar
â”‚Â Â  â””â”€â”€ trino-hive-postgres-docker-compose.yaml
â””â”€â”€ trino
    â””â”€â”€ etc
        â”œâ”€â”€ catalog
        â”‚Â Â  â”œâ”€â”€ delta.properties
        â”‚Â Â  â””â”€â”€ hive.properties
        â”œâ”€â”€ config.properties
        â”œâ”€â”€ jvm.config
        â””â”€â”€ node.properties

```

---

## âš™ï¸ Como Rodar o Projeto

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/seuusuario/data-lake-local.git
cd data-lake-local
```

### 2. Suba os serviÃ§os com Docker Compose (entre na pasta poc e execute o seguinte comando)
```bash
docker compose -f trino-hive-postgres-docker-compose.yaml up -d
```
Altere os caminhos de dentro do docker compose caso dÃª erro se necessÃ¡rio

### 3. Verifique os serviÃ§os
- Superset: [http://localhost:8088](http://localhost:8088)
- Trino UI: [http://localhost:8080](http://localhost:8080)
- MinIO Console: [http://localhost:9001](http://localhost:9001)
  - Acesso: `admin / admin123`

---
### 4. Crie um bucket e insira um csv de teste dentro do MinIO Console

## ğŸ—‚ï¸ Registrando tabelas no Hive via Trino
Acesse o Trino CLI ou Web UI e execute:
```sql
CREATE SCHEMA IF NOT EXISTS hive.test_minio
WITH (
  location = 's3a://bronze/test_minio/'
);

CREATE TABLE IF NOT EXISTS hive.test_minio.vendas (
  data VARCHAR,
  produto VARCHAR,
  categoria VARCHAR,
  preco VARCHAR,
  quantidade VARCHAR,
  total VARCHAR
)
WITH (
  external_location = 's3a://bronze/vendas/',
  format = 'CSV',
  skip_header_line_count = 1
);
```
> Obs: CSV sÃ³ aceita campos `VARCHAR` no Hive.

---

## ğŸ“Š Visualizando dados no Superset
1. Acesse o Superset em `http://localhost:8088`
2. VÃ¡ em `Data > Database` e crie uma nova conexÃ£o com:
   - Nome: Trino
   - String de conexÃ£o:
     ```
     trino://user@trino:8080/hive
     ```
3. Teste a conexÃ£o e salve
4. Agora vÃ¡ em `Data > Dataset` e selecione a tabela `vendas` para comeÃ§ar a criar dashboards ğŸš€

---

## ğŸ™‹â€â™‚ï¸ Por quÃª esse projeto?
Esse projeto nasceu da vontade de entender na prÃ¡tica como um ambiente de dados funciona sem depender da nuvem â€” ideal pra estudar, montar provas de conceito e criar portfÃ³lio.
Lembre-se: Esse projeto Ã© feito apenas para estudos, nÃ£o Ã© um repositÃ³rio oficial

---

## ğŸ“œ CrÃ©ditos e ReferÃªncias
- [Artigo do David Zbeda](https://david-dudu-zbeda.medium.com/setting-up-trino-with-hive-to-query-delta-lake-data-on-minio-a-scalable-big-data-solution-a7e2392e04f4)
- [DocumentaÃ§Ãµes oficiais do Trino, Hive, Delta e MinIO]

Armazene esse readme pra mim
